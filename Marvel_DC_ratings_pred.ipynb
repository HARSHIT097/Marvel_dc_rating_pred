{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor</th>\n",
       "      <th>Description</th>\n",
       "      <th>IMDB_Score</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>Votes</th>\n",
       "      <th>USA_Gross</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Eternals</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChloéZhao</td>\n",
       "      <td>AngelinaJolie,GemmaChan,RichardMadden,BarryKeo...</td>\n",
       "      <td>The saga of the Eternals, a race of immortal b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Loki</td>\n",
       "      <td>(2021– )</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TomHiddleston,OwenWilson,SophiaDiMartino,Richa...</td>\n",
       "      <td>A new Marvel chapter with Loki at its center.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Movie      Year                     Genre RunTime Rating  \\\n",
       "0           0  Eternals    (2021)    Action,Adventure,Drama     NaN    NaN   \n",
       "1           1      Loki  (2021– )  Action,Adventure,Fantasy     NaN    NaN   \n",
       "\n",
       "    Director                                              Actor  \\\n",
       "0  ChloéZhao  AngelinaJolie,GemmaChan,RichardMadden,BarryKeo...   \n",
       "1        NaN  TomHiddleston,OwenWilson,SophiaDiMartino,Richa...   \n",
       "\n",
       "                                         Description  IMDB_Score  Metascore  \\\n",
       "0  The saga of the Eternals, a race of immortal b...         NaN        NaN   \n",
       "1      A new Marvel chapter with Loki at its center.         NaN        NaN   \n",
       "\n",
       "  Votes USA_Gross Category  \n",
       "0   NaN       NaN   Marvel  \n",
       "1   NaN       NaN   Marvel  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOADING THE DATASET\n",
    "raw_df = pd.read_csv(\"DATA_SOURCE//Marvel_DC_imdb.csv\")\n",
    "raw_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "Movie           object\n",
       "Year            object\n",
       "Genre           object\n",
       "RunTime         object\n",
       "Rating          object\n",
       "Director        object\n",
       "Actor           object\n",
       "Description     object\n",
       "IMDB_Score     float64\n",
       "Metascore      float64\n",
       "Votes           object\n",
       "USA_Gross       object\n",
       "Category        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DC        1301\n",
       "Marvel     389\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1690 entries, 0 to 1689\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1690 non-null   int64  \n",
      " 1   Movie        1690 non-null   object \n",
      " 2   Year         1657 non-null   object \n",
      " 3   Genre        1683 non-null   object \n",
      " 4   RunTime      1407 non-null   object \n",
      " 5   Rating       1463 non-null   object \n",
      " 6   Director     1474 non-null   object \n",
      " 7   Actor        1660 non-null   object \n",
      " 8   Description  1690 non-null   object \n",
      " 9   IMDB_Score   1486 non-null   float64\n",
      " 10  Metascore    65 non-null     float64\n",
      " 11  Votes        1486 non-null   object \n",
      " 12  USA_Gross    64 non-null     object \n",
      " 13  Category     1690 non-null   object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 185.0+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0.00\n",
       "Movie           0.00\n",
       "Year            1.95\n",
       "Genre           0.41\n",
       "RunTime        16.75\n",
       "Rating         13.43\n",
       "Director       12.78\n",
       "Actor           1.78\n",
       "Description     0.00\n",
       "IMDB_Score     12.07\n",
       "Metascore      96.15\n",
       "Votes          12.07\n",
       "USA_Gross      96.21\n",
       "Category        0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "round(100*(raw_df.isnull().sum())/len(raw_df), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the NaN value of the mentioned two columns are high we are dropping it.\n",
    "USA_Gross 96.21\n",
    "Metascore 96.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor</th>\n",
       "      <th>Description</th>\n",
       "      <th>IMDB_Score</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Eternals</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChloéZhao</td>\n",
       "      <td>AngelinaJolie,GemmaChan,RichardMadden,BarryKeo...</td>\n",
       "      <td>The saga of the Eternals, a race of immortal b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Loki</td>\n",
       "      <td>(2021– )</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TomHiddleston,OwenWilson,SophiaDiMartino,Richa...</td>\n",
       "      <td>A new Marvel chapter with Loki at its center.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marvel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Movie      Year                     Genre RunTime Rating  \\\n",
       "0           0  Eternals    (2021)    Action,Adventure,Drama     NaN    NaN   \n",
       "1           1      Loki  (2021– )  Action,Adventure,Fantasy     NaN    NaN   \n",
       "\n",
       "    Director                                              Actor  \\\n",
       "0  ChloéZhao  AngelinaJolie,GemmaChan,RichardMadden,BarryKeo...   \n",
       "1        NaN  TomHiddleston,OwenWilson,SophiaDiMartino,Richa...   \n",
       "\n",
       "                                         Description  IMDB_Score Votes  \\\n",
       "0  The saga of the Eternals, a race of immortal b...         NaN   NaN   \n",
       "1      A new Marvel chapter with Loki at its center.         NaN   NaN   \n",
       "\n",
       "  Category  \n",
       "0   Marvel  \n",
       "1   Marvel  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df1 = raw_df.drop(['USA_Gross', 'Metascore'], axis=1)\n",
    "raw_df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0.00\n",
       "Movie           0.00\n",
       "Year            1.95\n",
       "Genre           0.41\n",
       "RunTime        16.75\n",
       "Rating         13.43\n",
       "Director       12.78\n",
       "Actor           1.78\n",
       "Description     0.00\n",
       "IMDB_Score     12.07\n",
       "Votes          12.07\n",
       "Category        0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "round(100*(raw_df1.isnull().sum())/len(raw_df1), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1690 entries, 0 to 1689\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1690 non-null   int64  \n",
      " 1   Movie        1690 non-null   object \n",
      " 2   Year         1657 non-null   object \n",
      " 3   Genre        1683 non-null   object \n",
      " 4   RunTime      1407 non-null   object \n",
      " 5   Rating       1463 non-null   object \n",
      " 6   Director     1474 non-null   object \n",
      " 7   Actor        1660 non-null   object \n",
      " 8   Description  1690 non-null   object \n",
      " 9   IMDB_Score   1486 non-null   float64\n",
      " 10  Votes        1486 non-null   object \n",
      " 11  Category     1690 non-null   object \n",
      "dtypes: float64(1), int64(1), object(10)\n",
      "memory usage: 158.6+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label Encoding (Handling String values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessing from sklearn\n",
    "from sklearn import preprocessing\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "# 2/3. FIT AND TRANSFORM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6ad3aa6dc769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use df.apply() to apply le.fit_transform to all columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw_df2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_df1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmarvelvsdc_df_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m    255\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "raw_df2 = raw_df1.apply(le.fit_transform)\n",
    "marvelvsdc_df_2.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical = list(raw_df1.select_dtypes(include=['object']).columns.values)\n",
    "for cat in categorical:\n",
    "    print(cat)\n",
    "    raw_df1[cat].fillna('UNK', inplace=True)\n",
    "    raw_df1[cat] = le.fit_transform(raw_df1[cat])\n",
    "    #df[cat] = le.fit_transform(df[cat].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1[\"IMDB_Score\"] = le.fit_transform(raw_df1[\"IMDB_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "round(100*(raw_df1.isnull().sum())/len(raw_df1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation Approach with KNNImputer\n",
    "k-Nearest Neighbors (kNN) can help to impute the values of missing data. Sociologists and\n",
    "community researchers suggest that human beings live in a community because neighbors\n",
    "generate a feeling of security and safety, attachment to community, and relationships that bring\n",
    "out a community identity through participation in various activities.\n",
    "A similar imputation methodology that works on data is k-Nearest Neighbours (kNN) that\n",
    "identifies the neighboring points through a measure of distance and the missing values can be\n",
    "estimated using completed values of neighboring observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5,weights='uniform',metric='nan_euclidean')\n",
    "imputer.fit_transform(raw_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.figure(figsize= [5,10])\n",
    "\n",
    "#Apply matplotlib functionalities\n",
    "#Change the colour of bins to green\n",
    "#Change the number of bins\n",
    "#Create a distribution plot for rating\n",
    "#import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.distplot(raw_df1.Rating, bins = 40, color = \"yellow\")\n",
    "plt.title(\"Distribution of Rating overs the Graph\", fontsize = 20, fontweight = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [11,7])\n",
    "sns.heatmap(raw_df1.corr(),annot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling the Values -- We will use MinMax scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "num_vars = ['Unnamed: 0', 'Movie', 'Year', 'Genre', 'RunTime', 'Rating', 'Director',\n",
    "            'Actor', 'Description', 'IMDB_Score', 'Votes', 'Category']\n",
    "raw_df1[num_vars] = scaler.fit_transform(raw_df1[num_vars])\n",
    "raw_df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Putting feature variable to X\n",
    "X = raw_df1.drop(['Rating'], axis=1)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = raw_df1['Rating']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
    "                                                    test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building\n",
    "\n",
    "Let's start by splitting our data into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE and LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Running RFE with the output number of the variable equal to 10\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm, 11) # running RFE\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking VIF\n",
    "Variance Inflation Factor or VIF, gives a basic quantitative idea about how much the\n",
    "feature variables are correlated with each other. It is an extremely important parameter to\n",
    "test our linear model. The formula for calculating VIF is:\n",
    "Features VIF is\n",
    "\n",
    "V IFi =1/1−Ri2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the common ways to check for multicollinearity is the Variance Inflation Factor (VIF):\n",
    "\n",
    "VIF=1, Very Less Multicollinearity\n",
    "VIF<5, Moderate Multicollinearity\n",
    "VIF>5, Extreme Multicollinearity (This is what we have to avoid)\n",
    "Compute the VIF scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Create a dataframe that will contain the names of all the feature variables and th\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Category'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and th\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Actor'], axis=1)\n",
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Movie'], axis=1)\n",
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and th\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['IMDB_Score'], axis=1)\n",
    "X_train = X_train.drop(['RunTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and th\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Unnamed: 0'], axis=1)\n",
    "# Build a third fitted model\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train)\n",
    "lr_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "# Print the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Analysis of the train data\n",
    "\n",
    "So, now to check if the error terms are also normally distributed (which is infact, one of\n",
    "the major assumptions of linear regression), let us plot the histogram of the error terms\n",
    "and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnt = lr_2.predict(X_train_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries for plots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_cnt), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20) # Plot heading\n",
    "plt.xlabel('Errors', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Predictions\n",
    "X_test.columns\n",
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our model to make predictions.\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_test_new = X_test[X_train.columns]\n",
    "# Adding a constant variable\n",
    "X_test_new = sm.add_constant(X_test_new)\n",
    "# Making predictions\n",
    "y_pred = lr_2.predict(X_test_new)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_2.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test,y_pred)\n",
    "fig.suptitle('y_test vs y_pred', fontsize=20) # Plot heading\n",
    "plt.xlabel('y_test', fontsize=18) # X-label\n",
    "plt.ylabel('y_pred', fontsize=16) # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_1 = pd.DataFrame(y_pred)\n",
    "\n",
    "# Let's see the head\n",
    "y_pred_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "X_test_df['ID'] = X_test_df.index\n",
    "\n",
    "# Removing index for both dataframes to append them side by side\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "X_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Appending y_test_df and y_pred_1\n",
    "y_pred_final = pd.concat([X_test_df, y_pred_1],axis=1)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column\n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Rating'})\n",
    "y_pred_final.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
